

# üìä Analisi Dati ‚Äì NSL-KDD Dataset
 
L‚Äôattivit√† di analisi dati condotta sul dataset **NSL-KDD** ha avuto un duplice obiettivo:  
1. fornire una comprensione approfondita della struttura e delle propriet√† dei dati;  
2. individuare le criticit√† e le trasformazioni necessarie affinch√© il dataset possa essere impiegato in modo efficace in modelli di *Machine Learning* per la realizzazione di un sistema di **Intrusion Detection (IDS)**.

## ‚ÑπÔ∏è Documentazione del dataset
Per una descrizione dettagliata della struttura del dataset, delle feature e delle etichette disponibili, 
si rimanda alla pagina [data/nsl-kdd/index.html](data/nsl-kdd/index.html).

---
## Tecnologie utilizzate

# Pandas

Libreria di riferimento in Python per la manipolazione e l‚Äôanalisi di dataset tabellari,  utilizzata per il caricamento del dataset NSL-KDD, l‚Äôassegnazione dei nomi ufficiali delle colonne, l‚Äôesplorazione preliminare tramite metodi descrittivi (head(), shape(), describe()),
 l‚Äôanalisi della distribuzione delle classi (value_counts()).

Grazie alla struttura dei DataFrame, Pandas consente di trattare i dati in modo analogo a una tabella relazionale, rendendo possibili operazioni complesse di filtraggio, raggruppamento e trasformazione con poche righe di codice.
Nel contesto di un IDS, questo strumento ha permesso di passare dal dataset grezzo a una base dati strutturata e coerente, pronta per successive elaborazioni.

# Matplotlib

 Libreria base per la visualizzazione grafica in Python,
 √® stata utilizzata in combinazione con Seaborn per la generazione di grafici a barre (countplot), la rappresentazione di boxplot per individuare outlier e la costruzione di heatmap per l‚Äôanalisi delle correlazioni tra variabili.

# Seaborn

Libreria di data visualization costruita su Matplotlib, con un orientamento specifico verso analisi statistiche, adottata per la necessit√† di ottenere grafici chiari, leggibili e ottimizzati per l‚Äôinterpretazione dei dati.

Le funzionalit√† impiegate includono grafici di distribuzione delle classi (countplot),

boxplot per la rilevazione di valori anomali,

heatmap della matrice di correlazione tra variabili numeriche.

Rispetto a Matplotlib, Seaborn offre un livello di astrazione superiore che consente di focalizzarsi sull‚Äôanalisi piuttosto che sulla configurazione estetica.
In un IDS, strumenti di questo tipo supportano la comprensione immediata delle caratteristiche distintive tra traffico normale e malevolo.

# Scikit-Learn

Scikit-Learn (sklearn) √® la libreria Python pi√π diffusa per l‚Äôapprendimento automatico e nella fase di analisi dati √® stata impiegata per l‚Äôencoding delle variabili categoriche (protocol_type, service, flag) mediante LabelEncoder, la trasformazione dell‚Äôetichetta target (normal/attack), e per la standardizzazione delle feature numeriche tramite StandardScaler.

Questi passaggi di preprocessing hanno reso il dataset numericamente consistente e normalizzato, condizione indispensabile per addestrare modelli di Machine Learning.
Senza tali trasformazioni, i modelli sarebbero stati soggetti a bias e instabilit√† dovute a scale eterogenee o a input non numerici.

# Random Forest

La Random Forest √® stata impiegata per analizzare il dataset e identificare le feature pi√π rilevanti per distinguere traffico normale da attacchi.

- Le variabili `src_bytes`, `dst_bytes`, `same_srv_rate`, `dst_host_srv_count` e `flag` si sono dimostrate tra le pi√π discriminanti.  

- L‚Äôanalisi ha evidenziato che un sottoinsieme di **15‚Äì20 feature** √® sufficiente a spiegare oltre il 70% della capacit√† predittiva del modello.  


## 1. Struttura e distribuzione delle classi
L‚Äôanalisi preliminare ha confermato che il dataset contiene **41 variabili descrittive**, di natura eterogenea (numeriche, categoriche, contatori, frequenze), e due colonne aggiuntive:  
- `label` ‚Üí etichetta multiclass che identifica traffico normale o tipologie specifiche di attacco (DoS, Probe, R2L, U2R).  
- `difficulty` ‚Üí indice della complessit√† dell‚Äôistanza, utile per studi avanzati ma non necessario in fase di training.  

La distribuzione delle classi risulta **fortemente sbilanciata**: alcune tipologie di attacco, come *neptune* e *smurf*, sono sovrarappresentate, mentre altre, quali *spy* o *perl*, compaiono in quantit√† marginali.  

Lo sbilanciamento √® un fenomeno noto nei dataset di sicurezza informatica: gli attacchi reali seguono tipicamente una distribuzione ‚Äúlong tail‚Äù, dove poche famiglie sono molto diffuse e molte altre sono rare.  
In ambito di *data analysis*, √® essenziale rilevare questo aspetto per evitare che i modelli di classificazione risultino **biased** verso le classi maggioritarie.  

In questa fase √® stata introdotta un‚Äôetichetta **binaria** (`binary_label`: *normal* vs *attack*) al fine di ridurre la complessit√† del problema e focalizzarsi sull‚Äôobiettivo primario di un IDS: distinguere il traffico lecito da quello malevolo.  
Tale approccio consente inoltre di ottenere valutazioni pi√π stabili, rinviando a una fase successiva l‚Äôeventuale estensione al problema **multi-classe**.

---

## 2. Statistiche descrittive delle variabili numeriche
Le statistiche di base (medie, deviazioni standard, quartili) hanno mostrato valori con range molto estesi e presenza di numerosi **outlier**. Ad esempio, feature come `src_bytes` e `dst_bytes` presentano distribuzioni altamente asimmetriche, con valori eccezionalmente elevati in corrispondenza di specifiche istanze di attacco.

In un contesto di sicurezza, gli outlier non rappresentano rumore da eliminare, bens√¨ spesso corrispondono a **pattern anomali reali** (e.g., attacchi DoS caratterizzati da volumi di traffico anomali).  
√à quindi importante **preservarli** come indizi utili per la classificazione, ma al contempo ridurre gli effetti distorsivi delle scale diverse mediante tecniche di normalizzazione.

### Soluzione
Si √® optato per l‚Äôapplicazione di uno **StandardScaler**, al fine di portare tutte le variabili numeriche su una scala comparabile (media = 0, deviazione standard = 1).  
Ci√≤ risulta particolarmente rilevante per algoritmi basati su distanze o gradienti, come regressione logistica, SVM o reti neurali.

---

## 3. Correlazioni tra variabili
La matrice di correlazione ha evidenziato la presenza di coppie di feature altamente collegate (e.g., `serror_rate` ‚Üî `srv_serror_rate`, `rerror_rate` ‚Üî `srv_rerror_rate`).  
Questa ridondanza √® tipica di dataset costruiti su metriche di rete, dove variabili derivate condividono l‚Äôinformazione di base.

Feature fortemente correlate possono determinare:  
- inefficienza computazionale (modelli pi√π complessi senza reale incremento informativo);  
- rischio di *multicollinearit√†* in algoritmi parametrici (regressione, reti neurali), con conseguente perdita di interpretabilit√†.  

---
## 4. ## Feature Selection con Random Forest

Per ridurre la ridondanza e identificare le variabili pi√π rilevanti ai fini della classificazione, √® stata applicata una **Feature Selection basata su Random Forest**.  
Questa tecnica sfrutta l‚Äôimportanza delle variabili (`feature importance`), calcolata come riduzione media dell‚Äôimpurit√† ottenuta quando una feature viene utilizzata per effettuare split all‚Äôinterno degli alberi.

### Risultati principali
- Le feature **pi√π importanti** risultano essere `src_bytes`, `dst_bytes`, `same_srv_rate`, `dst_host_srv_count`, `dst_host_same_srv_rate` e `flag`.  
  Queste variabili descrivono la quantit√† di traffico scambiato e le caratteristiche delle connessioni TCP/servizi, elementi chiave per individuare anomalie.  
- Alcune feature, come `num_outbound_cmds`, `is_host_login` e `su_attempted`, hanno importanza trascurabile (< 0.001), indicando che possono essere eliminate senza perdita di accuratezza.  
- La **curva cumulativa** mostra che le prime ~15‚Äì20 feature spiegano gi√† oltre il **70‚Äì80% dell‚Äôimportanza totale**, suggerendo che un sottoinsieme ristretto di variabili √® sufficiente a mantenere buone performance del modello. 

---

## 5. Preprocessing
Le operazioni di preprocessing hanno incluso:  
- encoding delle variabili categoriche (`protocol_type`, `service`, `flag`) ‚Üí necessarie poich√© gli algoritmi di ML richiedono input numerici;  
- encoding binario della variabile target (`normal`=0, `attack`=1);  
- standardizzazione delle variabili numeriche.  

### Motivazione metodologica
Tali trasformazioni garantiscono che il dataset sia in una forma **consistente e idonea** all‚Äôaddestramento di modelli di *Machine Learning*, evitando bias legati a scale eterogenee o input non numerici.

---


##  Conclusione finale
Il dataset NSL-KDD, dopo la fase di analisi e preprocessing, risulta **pronto per l‚Äôaddestramento di modelli di Machine Learning**.  
Le scelte metodologiche adottate (binaria vs multi-classe, preservazione outlier, scaling uniforme) sono state guidate dalla natura del problema di **Intrusion Detection**, dove l‚Äôobiettivo primario non √® l‚Äôaccuratezza globale, bens√¨ la capacit√† di individuare **eventi rari e anomali**.  

---------------

#  logAIzer ‚Äì Modulo Machine Learning

Il modulo di Machine Learning di logAIzer implementa una pipeline per l‚Äôaddestramento e la valutazione di modelli di classificazione sul dataset NSL-KDD, con l‚Äôobiettivo di sviluppare un sistema di Intrusion Detection (IDS) basato su tecniche di analisi dati e apprendimento automatico.

 #  Struttura del progetto
src/

‚îÇ‚îÄ‚îÄ dataloader.py      # Caricamento e preprocessing dei dati
‚îÇ‚îÄ‚îÄ models.py          # Definizione dei modelli ML
‚îÇ‚îÄ‚îÄ train.py           # Pipeline di training e validazione
‚îÇ‚îÄ‚îÄ evaluate.py        # Metriche di valutazione e report
config.json            # File di configurazione
config_schema.json     # Schema JSON per validazione
reports/               # Output di metriche e confusion matrix


La struttura modulare rende il codice leggibile, estendibile e facilmente manutenibile, in linea con le best practice accademiche e industriali.

#  Configurazione

Tutti i parametri sono definiti nel file config.json, validato tramite config_schema.json.
Questo approccio garantisce flessibilit√† e riduce la possibilit√† di errori manuali.

Esempio di config.json

``` json
{
  "data": {
    "train_path": "data/nsl-kdd/KDDTrain+.TXT",
    "test_path": "data/nsl-kdd/KDDTest+.TXT",
    "binary": true
  },
  "models": {
    "logistic_regression": {
      "enabled": true,
      "max_iter": 1000,
      "class_weight": "balanced",
      "solver": "lbfgs"
    },
    "random_forest": {
      "enabled": true,
      "n_estimators": 100,
      "class_weight": "balanced",
      "random_state": 42
    }
  },
  "output": {
    "reports_dir": "reports/"
  }
}
```

 #  Componenti principali
üîπ DataLoader (dataloader.py)

Carica i dataset train/test.

Esegue preprocessing:

encoding delle variabili categoriche (protocol_type, service, flag),

conversione etichetta binaria (normal = 0, attack = 1),

standardizzazione delle feature numeriche.


üîπ Modelli (models.py)

Sono stati implementati due modelli baseline:

Logistic Regression ‚Üí modello lineare, semplice e interpretabile.

Random Forest ‚Üí modello non lineare, robusto a outlier e feature ridondanti.

Entrambi utilizzano class_weight="balanced" per gestire lo sbilanciamento delle classi.

üîπ Training (train.py)

Carica configurazione da config.json.

Esegue addestramento dei modelli abilitati.

Valuta le performance sui dati di test.

Integra il modulo evaluate.py per salvare i risultati.

üîπ Valutazione (evaluate.py)

Per ogni modello vengono generati:

Classification report (precision, recall, f1-score, support) ‚Üí salvato in JSON.

Confusion matrix ‚Üí salvata come PNG.

#  Metriche adottate

Poich√© il dataset √® sbilanciato, l‚Äôaccuracy non √® sufficiente.
Sono state privilegiate metriche pi√π informative per un IDS:

Precision ‚Üí ridurre i falsi positivi.

Recall ‚Üí intercettare il maggior numero di attacchi (falsi negativi critici).

F1-score ‚Üí equilibrio tra precision e recall.

Confusion matrix ‚Üí visualizzazione immediata delle performance.

#  Esecuzione

Dopo aver installato le dipendenze:

pip install -r requirements.txt


lanciare il training con:

python src/train.py --config config.json --schema config_schema.json

 # Output atteso

Nella cartella reports/ vengono prodotti:

lr_report.json ‚Üí metriche Logistic Regression

lr_cm.png ‚Üí confusion matrix Logistic Regression

rf_report.json ‚Üí metriche Random Forest

rf_cm.png ‚Üí confusion matrix Random Forest

#  Considerazioni finali

La pipeline implementata √® modulare, configurabile e riproducibile.

Le scelte metodologiche (binary classification, scaling uniforme, gestione sbilanciamento) sono state guidate dalle caratteristiche del dataset e dalle esigenze di un IDS reale.

Il modulo ML costituisce la base per sviluppi futuri, tra cui:

testing di modelli pi√π avanzati (XGBoost, Reti Neurali),

applicazione di tecniche di bilanciamento (SMOTE, cost-sensitive learning),

classificazione multi-classe per distinguere le diverse famiglie di attacco,

integrazione con tecniche di early stopping e logging (TensorBoard).
